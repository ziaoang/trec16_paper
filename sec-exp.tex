\section{Experiment}
The evaluation of TREC 2016 Real-time Summarization track takes place from
August 2, 2016 UTC to August 11, 2016 UTC.
And there are 203 interest profiles which participants will be responsible for tracking.
During the evaluation period, participants must maintain a running system
that continuously monitors the tweet sample stream.

For the push notifications scenario, the primary evaluation metrics
include Expected Gain (EG) and Normalized Cumulative Gain (nCG).
In the EG1 and nCG1 variants of the metrics, on a ``silent day'',
the system receives a score of one (i.e., perfect score) if it does not push any tweets,
or zero otherwise. In the EG0 and nCG0 variants of the metrics, for a silent day,
all systems receive a gain of zero no matter what they do.
Table \ref{tab:resA} shows the performance of our submitted three runs.
We could observe that in every run, EG1 and nCG1 are much larger than EG0 and nCG0,
which means our proposed system could recognise the ``silent day''
and make no push actions to avoid bothering users.
We use different text similarity algorithms in different runs
but their performance are similar, which could tell the robustness
of the nagetive KL-divergence distance with different smoothing strategies.

\begin{table}[htbp]
\centering
\caption{Performance of the Push Notifications Scenario.}
\label{tab:resA}
\begin{tabular}{lrrrr}
\hline
Run ID&EG1&EG0&nCG1&nCG0\\
\hline
PKUICSTRunA1&0.2342&0.0342&\textbf{0.2447}&0.0447\\
PKUICSTRunA2&\textbf{0.2347}&\textbf{0.0400}&0.2433&\textbf{0.0487}\\
PKUICSTRunA3&0.2329&0.0311&0.2343&0.0325\\
\hline
\end{tabular}
\end{table}

Table \ref{tab:resB} reports our results for the email digest scenario.
The primary evaluation metric is nDCG1.
As it turns out, PKUICSTRunB3 significantly outperforms both other runs,
indicating that the Simhash method for novelty verification module is successful in identifying novel tweets.
Both PKUICSTRunB1 and PKUICSTRunB2 adopt the KL-divergence language model,
with DIR(Bayesian Smoothing with Dirichlet Priors) smoothing and JM(Jelinek-Mercer method) respectively.
And the uniform novel thresholds are $\gamma=0.73$ and $\gamma=0.72$ training on the TREC 15 dataset.
From Table \ref{tab:resB}, we can see that nDCG1 and nDCG0 are the same in PKUICSTRunB1 and PKUICSTRunB2,
which means on each ``silent day'', our system still pushed some tweets that are regarded as unrelated ones.
Obviously, the thresholds do not fit well. Further investigation and experiments are needed to solve this issue.

\begin{table}[htbp]
\centering
\caption{Performance of the Email Digest Scenario.}
\label{tab:resB}
\begin{tabular}{lrrr}
\hline
Run ID&nDCG1&nDCG0\\
\hline
PKUICSTRunB1&0.1423&0.1423\\
PKUICSTRunB2&0.1569&\textbf{0.1569}\\
PKUICSTRunB3&\textbf{0.2348}&0.0151\\
\hline
\end{tabular}
\end{table}


