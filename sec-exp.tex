\section{Result and Analysis}
The evaluation of TREC 2016 Real-time Summarization track take place from Tuesday, August 2, 2016 00:00:00 UTC to August 11, 2016 23:59:59 UTC. And there are 203 interest profiles which participants will be responsible for tracking. During the evaluation period, participants must maintain a running system that continuously monitors the tweet sample stream.

For scenario A,  Table \ref{tab:resA} show the performance of our submitted three runs.
The primary evaluation metric for scenario A is EG-1. **** task A description.

\begin{table}[htbp]
\centering
\caption{Performance of submitted runs for scenario A}
\label{tab:resA}
\begin{tabular}{lrrrr}
\hline
Run ID&ELG&nCG\\
\hline
PKUICSTRunA1&0.1415&0.1566\\
PKUICSTRunA2&\textbf{0.3175}&\textbf{0.3127}\\
PKUICSTRunA3&0.1382&0.1711\\
\hline
\end{tabular}
\end{table}

Table \ref{tab:resB} reports our results for scenario B periodic email digest. The primary evaluation metric is nDCG1. As it turns out, PKUICSTRunB3 significantly outperforms both other runs, indicating that the Simhash method for novelty verification module is successful in identifying novel tweets. Both PKUICSTRunB1 and PKUICSTRunB2 adopt the KL-divergence language model, with DIR(Bayesian Smoothing with Dirichlet Priors) smoothing and JM(Jelinek-Mercer method) respectively. And the uniform novel thresholds are $\gamma=0.73$ and $\gamma=0.72$ training on the TREC 15 dataset. From Table \ref{tab:resB}, we can see that nDCG1 and nDCG0 are the same in PKUICSTRunB1 and PKUICSTRunB2, which means on each $"$silent day$"$, our system still pushed some tweets that are regarded as unrelated ones. Obviously, the thresholds do not fit well. Further investigation and experiments are needed to solve this issue.

\begin{table}[htbp]
\centering
\caption{Performance of submitted runs for scenario A}
\label{tab:resB}
\begin{tabular}{lrrr}
\hline
Run ID&nDCG1&nDCG0\\
\hline
PKUICSTRunB1&0.1423&0.1423\\
PKUICSTRunB2&0.1569&0.1569\\
PKUICSTRunB3&\textbf{0.2348}&0.0151\\
\hline
\end{tabular}
\end{table}

\section{Conclusion}
In this work, we present our systems for TREC 2016 Real-Time Summarization Track.
**********In the push notification on a mobile phone scenario, 
we apply an adaptive timely query-biased filtering framework which monitors and estimates the twitter stream with given interest profiles continuously and immediately.
In the email digest scenario,
We apply web-based query expansion using language model to rank candidate tweets and then we leverage two kinds of strategies to measure novelty between tweets. Experimental results show our effectiveness and efficiency of our system in both tasks.





